{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises Level 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question \n",
    "1. Write a function which count number of lines and number of words in a text. All the files are in the data the folder:\n",
    "   a)  Read obama_speech.txt file and count number of lines and words\n",
    "   b) Read michelle_obama_speech.txt file and count number of lines and words\n",
    "   c) Read donald_speech.txt file and count number of lines and words\n",
    "   d) Read melina_trump_speech.txt file and count number of lines and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama Speech\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './obama_speech.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mThe number of words in the document is \u001b[39m\u001b[39m'\u001b[39m, no_words)\n\u001b[0;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mObama Speech\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m read_count_lines(\u001b[39m'\u001b[39;49m\u001b[39m./obama_speech.txt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     19\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mMichelle Obama Speech\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m read_count_lines(\u001b[39m'\u001b[39m\u001b[39m./michelle_obama_speech.txt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[27], line 3\u001b[0m, in \u001b[0;36mread_count_lines\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_count_lines\u001b[39m(x):\n\u001b[1;32m----> 3\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m (x) \u001b[39mas\u001b[39;00m d:\n\u001b[0;32m      4\u001b[0m         lines_list \u001b[39m=\u001b[39m d\u001b[39m.\u001b[39mreadlines()\n\u001b[0;32m      5\u001b[0m         no_of_lines \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(lines_list)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './obama_speech.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_count_lines(x):\n",
    "    with open (x) as d:\n",
    "        lines_list = d.readlines()\n",
    "        no_of_lines = len(lines_list)\n",
    "\n",
    "        no_words = 0\n",
    "        for i in lines_list :\n",
    "            doc_words = re.sub(r'[^\\w\\s]','', i)\n",
    "            words = i.split()\n",
    "            no_words += len(words)\n",
    "            \n",
    "\n",
    "        print('The number of lines in the document is ', no_of_lines)\n",
    "        print('The number of words in the document is ', no_words)\n",
    "\n",
    "print('Obama Speech')\n",
    "read_count_lines('./obama_speech.txt')\n",
    "print('Michelle Obama Speech')\n",
    "read_count_lines('./michelle_obama_speech.txt')\n",
    "print('Trump Speech')\n",
    "read_count_lines('./donald_speech.txt')\n",
    "print('Melina Trump Speech')\n",
    "read_count_lines('./melina_trump_speech.txt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question \n",
    "2. Read the countries_data.json data file in data directory, create a function that finds the ten most spoken languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('English', 91), ('French', 45), ('Arabic', 25), ('Spanish', 24), ('Portuguese', 9), ('Russian', 9), ('Dutch', 8), ('German', 7), ('Chinese', 5), ('Serbian', 4)]\n",
      "[('English', 91), ('French', 45), ('Arabic', 25)]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def most_spoken_languages(filename,countries):\n",
    "    file = open(filename , encoding=\"UTF8\")\n",
    "    Lang_dict =json.loads(file.read())\n",
    "    languages = []\n",
    "    for i in range(len(Lang_dict)):\n",
    "        languages.extend(Lang_dict[i]['languages'])\n",
    "    lang = {}\n",
    "    for language in languages:\n",
    "        lang[language] = lang.get(language,0) + 1\n",
    "    sorted_lang = sorted(lang.items(), key= lambda x:x[1],reverse=True)\n",
    "    top_langs = []\n",
    "    for i in range(countries):\n",
    "      top_langs.append(sorted_lang[i])\n",
    "    return top_langs\n",
    "\n",
    "print(most_spoken_languages('./data/countries_data.json', 10))\n",
    "print(most_spoken_languages('./data/countries_data.json', 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question\n",
    "3. Read the countries_data.json data file in data directory, create a function that creates a list of the ten most populated countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Country': 'China', 'Population': 1377422166}, {'Country': 'India', 'Population': 1295210000}, {'Country': 'United States of America', 'Population': 323947000}, {'Country': 'Indonesia', 'Population': 258705000}, {'Country': 'Brazil', 'Population': 206135893}, {'Country': 'Pakistan', 'Population': 194125062}, {'Country': 'Nigeria', 'Population': 186988000}, {'Country': 'Bangladesh', 'Population': 161006790}, {'Country': 'Russian Federation', 'Population': 146599183}, {'Country': 'Japan', 'Population': 126960000}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Country': 'China', 'Population': 1377422166},\n",
       " {'Country': 'India', 'Population': 1295210000},\n",
       " {'Country': 'United States of America', 'Population': 323947000}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_populated_countries(filename,countries):\n",
    "    file = open(filename , encoding=\"UTF8\")\n",
    "    Lang_dict =json.loads(file.read())\n",
    "    population = {}\n",
    "    for i in range(len(Lang_dict)):\n",
    "        keys = Lang_dict[i]['name']\n",
    "        values = Lang_dict[i]['population']\n",
    "        population[keys] = values\n",
    "    sorted_pop = dict(sorted(population.items(), key= lambda x:x[1],reverse=True))\n",
    "\n",
    "    most_pop = []\n",
    "    for i in list(sorted_pop.items()) [:countries] :\n",
    "        most_pop.append({\"Country\" : i[0], \"Population\" : i[1]})\n",
    "    return most_pop\n",
    "\n",
    "print(most_populated_countries('./data/countries_data.json', 10))\n",
    "most_populated_countries('./data/countries_data.json', 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb9b610eab4921576ab997c09d0c1c552d2f49ec8c532f5ef2f9f88daad97359"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
